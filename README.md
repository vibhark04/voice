# Speech Detection System for Verbally Impaired People

[![Python](https://img.shields.io/badge/python-3.9%2B-blue)](https://www.python.org/)  
[![PyTorch](https://img.shields.io/badge/pytorch-2.x-red)](https://pytorch.org/)  
[![Build Status](https://img.shields.io/badge/build-passing-brightgreen)](#)  
[![Made with â¤ï¸](https://img.shields.io/badge/Made%20with-Deep%20Learning-red)](#)

---

## ğŸ“– Overview  

This project explores how **muscle signals (EMG)** recorded from the face/jaw can be translated into **natural-sounding speech** using **deep learning**.  

The pipeline combines:  
- **Temporal Convolutional Networks (TCN)** for mapping EMG â†’ MFCCs (speech features).  
- **Generative Adversarial Networks (GAN)** for generating realistic audio.  

The ultimate goal is a **silent speech interface** â€” technology that allows communication without vocalizing aloud.  

---

## ğŸ—ï¸ System Architecture  

flowchart TD
    A [Silent EMG Input] --> B[Translator (TCN)]
    B --> C[Speech Features (MFCCs)]
    C --> D[Artist (Generator)]
    D --> E[Judge (Discriminator)]
    E -->|feedback| D
    D --> F[Generated Audio]
    F --> G[ASR Transcription & Evaluation]
ğŸ“‚ Data Requirements
Voiced EMG (*_emg.npy) â†’ Muscle activity while speaking aloud

Voiced Audio (*_audio_clean.flac) â†’ Ground truth speech

Silent EMG (*_emg.npy) â†’ Muscle activity while mouthing silently

Helper Files (.json, _button.npy) â†’ Timing and segmentation

âš™ï¸ Installation
Clone the repo and install dependencies:

bash
Copy code
git clone https://github.com/your-username/silent-emg-speech.git
cd silent-emg-speech
pip install -r requirements.txt
Core Libraries:

PyTorch

NumPy

SciPy

Librosa

Matplotlib

Scikit-learn

â–¶ï¸ Usage
1. Training
python
Copy code
from pipeline import train_pipeline

train_pipeline(
    silent_emg_file="3_emg.npy",
    voiced_emg_file="1_emg.npy",
    voiced_audio_file="1_audio_clean.flac",
    json_file="timing.json",
    silent_button_file="3_button.npy"
)
2. Inference / Testing
python
Copy code
from pipeline import test_pipeline

test_pipeline(
    new_emg_file="8_emg.npy",
    json_file="timing.json",
    button_file="8_button.npy"
)
ğŸ“Š Evaluation Metrics
The system generates a report card including:

WER (Word Error Rate) â†’ Speech accuracy

STOI (Short-Time Objective Intelligibility) â†’ Speech clarity

MCD (Mel-Cepstral Distortion) â†’ Voice similarity

Mel Spectrograms â†’ Visual sound comparison

Precision / Recall / F1 + Confusion Matrix â†’ Command classification

ğŸ“Œ Outputs
ğŸµ Synthesized Audio from silent EMG

ğŸ“ Text Transcription (ASR)

ğŸ“ˆ Evaluation Report with metrics & plots

ğŸ”® Future Work
Extend datasets for multilingual silent speech.

Explore transformer-based architectures.

Real-time EMG-to-speech applications for assistive devices.
